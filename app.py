import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import warnings
warnings.filterwarnings('ignore')
import numpy as np
import librosa
import joblib
import tensorflow as tf
import streamlit as st

def load_model_anyway(model_path):
    try:
        return tf.keras.models.load_model(model_path, compile=False)
    except Exception as e:
        st.error(f"Model loading failed: {str(e)}")
        st.stop()

def extract_features(file_path):
    try:
        y, sr = librosa.load(file_path, sr=22050)
        # Assuming your model was trained on a fixed duration, e.g., 3 seconds or 5 seconds.
        # Let's start by assuming the model expects a fixed 3-second audio input for its features.
        # This will ensure 'y' always has the same number of samples.
        fixed_duration_samples = sr * 3 # Adjust this '3' if your model expects a different fixed duration (e.g., 5 seconds)
        
        if len(y) < fixed_duration_samples:
            # Pad if audio is shorter than expected duration
            y = np.pad(y, (0, fixed_duration_samples - len(y)), 'constant')
        elif len(y) > fixed_duration_samples:
            # Truncate if audio is longer than expected duration
            y = y[:fixed_duration_samples]

        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
        mel_db = librosa.power_to_db(mel, ref=np.max)
        return np.expand_dims(np.expand_dims(mel_db, -1), 0)
    except Exception as e:
        st.error(f"Audio processing failed: {str(e)}")
        return None

st.set_page_config(page_title="Baby Cry Detector", page_icon="üë∂", layout="centered")

@st.cache_resource
def load_all():
    model = load_model_anyway("best_model.h5")
    encoder = joblib.load("label_encoder.pkl")
    if model:
        # ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§ø‡§§ ‡§á‡§®‡§™‡•Å‡§ü ‡§∂‡•á‡§™ ‡§ï‡•ã ‡§≤‡•â‡§ó ‡§ï‡§∞‡•á‡§Ç
        st.write(f"Model loaded. Expected input shape: {model.input_shape}")
    return model, encoder

model, encoder = load_all()

st.title("üë∂ Baby Cry Analyzer")
st.write("Upload a WAV file (2-5 seconds) of a baby crying")

uploaded_file = st.file_uploader("Choose file", type=["wav"])

if uploaded_file:
    st.audio(uploaded_file)
    with open("temp.wav", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    features = extract_features("temp.wav")
    if features is not None:
        # ‡§è‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡•à‡§ï‡•ç‡§ü‡•á‡§° ‡§´‡•Ä‡§ö‡§∞‡•ç‡§∏ ‡§ï‡•á ‡§∂‡•á‡§™ ‡§ï‡•ã ‡§≤‡•â‡§ó ‡§ï‡§∞‡•á‡§Ç
        st.write(f"Extracted features shape: {features.shape}")

        # ‡§Ø‡§π‡§æ‡§Å ‡§π‡§Æ ‡§è‡§ï ‡§¨‡•á‡§∏‡§ø‡§ï ‡§∂‡•á‡§™ ‡§ï‡§Æ‡•ç‡§™‡•á‡§ü‡§ø‡§¨‡§ø‡§≤‡§ø‡§ü‡•Ä ‡§ö‡•á‡§ï ‡§≠‡•Ä ‡§ú‡•ã‡§°‡§º ‡§∞‡§π‡•á ‡§π‡•à‡§Ç
        if model.input_shape and len(model.input_shape) == len(features.shape) and \
           all(s1 == s2 or s1 is None for s1, s2 in zip(model.input_shape[1:], features.shape[1:])):
            # ‡§∂‡•á‡§™ ‡§∏‡§Ç‡§ó‡§§ ‡§π‡•à‡§Ç, ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡•á‡§Ç
            pass
        else:
            # ‡§Ö‡§ó‡§∞ ‡§∂‡•á‡§™ ‡§Æ‡•à‡§ö ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞‡§§‡•á ‡§§‡•ã ‡§è‡§∞‡§∞ ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Ç ‡§î‡§∞ ‡§∞‡•Å‡§ï‡•á‡§Ç
            st.error(f"Input shape mismatch! Model expects {model.input_shape} but received {features.shape}. "
                     f"Please ensure audio length (2-5 seconds recommended) and processing match model's training.")
            st.stop() # ‡§Ø‡§π ‡§ê‡§™ ‡§ï‡•ã ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡§®‡•á ‡§∏‡•á ‡§∞‡•ã‡§ï‡•á‡§ó‡§æ ‡§Ö‡§ó‡§∞ ‡§∂‡•á‡§™ ‡§ó‡§≤‡§§ ‡§π‡•à

        pred = model.predict(features, verbose=0)[0]
        top_idx = np.argmax(pred)
        st.success(f"Most likely: {encoder.classes_[top_idx]} ({pred[top_idx]*100:.1f}%)")
    
    if os.path.exists("temp.wav"):
        os.remove("temp.wav")
