import os
# TensorFlow рдХреЗ рд▓реЙрдЧреНрд╕ рдХреЛ рдХрдо рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП (рдХрдо verbose рдЖрдЙрдЯрдкреБрдЯ)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import warnings
# рдЪреЗрддрд╛рд╡рдирд┐рдпреЛрдВ рдХреЛ рдЕрдирджреЗрдЦрд╛ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП
warnings.filterwarnings('ignore')

import numpy as np
import librosa
import joblib
import tensorflow as tf
import streamlit as st

# рдореЙрдбрд▓ рдХреЛ рд▓реЛрдб рдХрд░рдиреЗ рдХрд╛ рдлрдВрдХреНрд╢рди
# compile=False рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ рддрд╛рдХрд┐ рдореЙрдбрд▓ рдХреЛ рдлрд┐рд░ рд╕реЗ рдХрдВрдкрд╛рдЗрд▓ рдХрд░рдиреЗ рдХреА рдХреЛрд╢рд┐рд╢ рди рд╣реЛ,
# рдЬреЛ рдХрднреА-рдХрднреА рд╡рд░реНрдЬрди рдорд┐рд╕рдореИрдЪ рдХреЗ рдХрд╛рд░рдг рд╕рдорд╕реНрдпрд╛рдПрдБ рдкреИрджрд╛ рдХрд░ рд╕рдХрддрд╛ рд╣реИред
def load_model_anyway(model_path):
    try:
        return tf.keras.models.load_model(model_path, compile=False)
    except Exception as e:
        st.error(f"рдореЙрдбрд▓ рд▓реЛрдб рдХрд░рдиреЗ рдореЗрдВ рд╡рд┐рдлрд▓: {str(e)}")
        st.stop() # рдРрдк рдХреЛ рд░реЛрдХреЗрдВ рдпрджрд┐ рдореЙрдбрд▓ рд▓реЛрдб рдирд╣реАрдВ рд╣реЛ рдкрд╛рддрд╛

# рдСрдбрд┐рдпреЛ рд╕реЗ рдлреАрдЪрд░реНрд╕ рдирд┐рдХрд╛рд▓рдиреЗ рдХрд╛ рдлрдВрдХреНрд╢рди
def extract_features(file_path):
    try:
        # WAV рдлрд╝рд╛рдЗрд▓ рдХреЛ 22050 Hz рд╕реИрдВрдкрд▓ рд░реЗрдЯ рдкрд░ рд▓реЛрдб рдХрд░реЗрдВ
        y, sr = librosa.load(file_path, sr=22050)

        # рдореЙрдбрд▓ рдХреЛ (None, 128, 173) рдЖрдХрд╛рд░ рдХрд╛ рдЗрдирдкреБрдЯ рдЪрд╛рд╣рд┐рдПред
        # librosa рдХреЗ рдбрд┐рдлрд╝реЙрд▓реНрдЯ n_fft (2048) рдФрд░ hop_length (512) рдХреЗ рдЖрдзрд╛рд░ рдкрд░,
        # 173 рдлреНрд░реЗрдореНрд╕ рдХреЗ рд▓рд┐рдП рдЖрд╡рд╢реНрдпрдХ рд╕реИрдВрдкрд▓ рдХреА рд╕рдВрдЦреНрдпрд╛ рдХреА рдЧрдгрдирд╛ рдХрд░реЗрдВред
        n_fft = 2048
        hop_length = 512
        target_frames = 173
        
        # рдЖрд╡рд╢реНрдпрдХ рд╕реИрдВрдкрд▓ рдХреА рд╕рдВрдЦреНрдпрд╛ рдХреА рдЧрдгрдирд╛ рдХрд░реЗрдВ
        # (рдлреНрд░реЗрдореНрд╕ рдХреА рд╕рдВрдЦреНрдпрд╛ - 1) * рд╣реЙрдк_рд▓реЗрдВрде + n_fft
        # рдпрд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐ рдСрдбрд┐рдпреЛ рдХреА рд▓рдВрдмрд╛рдИ рдкрд░реНрдпрд╛рдкреНрдд рд╣реЛ
        target_samples = (target_frames - 1) * hop_length + n_fft
        
        # рдСрдбрд┐рдпреЛ рдХреЛ рдЖрд╡рд╢реНрдпрдХ рд╕реИрдВрдкрд▓ рдХреА рд╕рдВрдЦреНрдпрд╛ рддрдХ рдкреИрдб (pad) рдпрд╛ рдЯреНрд░рдВрдХреЗрдЯ (truncate) рдХрд░реЗрдВ
        if len(y) < target_samples:
            # рдпрджрд┐ рдСрдбрд┐рдпреЛ рдЕрдкреЗрдХреНрд╖рд┐рдд рдЕрд╡рдзрд┐ рд╕реЗ рдЫреЛрдЯрд╛ рд╣реИ, рддреЛ рдкреИрдб рдХрд░реЗрдВ
            y = np.pad(y, (0, target_samples - len(y)), 'constant')
        elif len(y) > target_samples:
            # рдпрджрд┐ рдСрдбрд┐рдпреЛ рдЕрдкреЗрдХреНрд╖рд┐рдд рдЕрд╡рдзрд┐ рд╕реЗ рд▓рдВрдмрд╛ рд╣реИ, рддреЛ рдЯреНрд░рдВрдХреЗрдЯ рдХрд░реЗрдВ
            y = y[:target_samples]

        # рдореЗрд▓ рд╕реНрдкреЗрдХреНрдЯреНрд░реЛрдЧреНрд░рд╛рдо рдирд┐рдХрд╛рд▓реЗрдВ
        # n_mels=128 рдореЙрдбрд▓ рдХреЗ 128 рдореЗрд▓ рдмреИрдВрдбреНрд╕ рд╕реЗ рдореЗрд▓ рдЦрд╛рддрд╛ рд╣реИ
        # n_fft рдФрд░ hop_length рдХреЛ рд╕реНрдкрд╖реНрдЯ рд░реВрдк рд╕реЗ рдирд┐рд░реНрджрд┐рд╖реНрдЯ рдХрд░реЗрдВ рддрд╛рдХрд┐ рдЧрдгрдирд╛рдПрдБ рд╕реБрд╕рдВрдЧрдд рд░рд╣реЗрдВ
        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=n_fft, hop_length=hop_length)
        mel_db = librosa.power_to_db(mel, ref=np.max)

        # рдЕрдм, рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ mel_db рдХреЗ рдлреНрд░реЗрдореНрд╕ рдХреА рд╕рдВрдЦреНрдпрд╛ (рджреВрд╕рд░рд╛ рдЖрдпрд╛рдо) рдмрд┐рд▓реНрдХреБрд▓ target_frames (173) рд╣реЛред
        # рд╡рд░реНрддрдорд╛рди рдлреНрд░реЗрдореНрд╕ рдХреА рд╕рдВрдЦреНрдпрд╛
        current_frames = mel_db.shape[1]

        if current_frames < target_frames:
            # рдпрджрд┐ рдХрдо рдлреНрд░реЗрдореНрд╕ рд╣реИрдВ, рддреЛ рдкреИрдб рдХрд░реЗрдВ
            padding_needed = target_frames - current_frames
            mel_db = np.pad(mel_db, ((0, 0), (0, padding_needed)), 'constant')
        elif current_frames > target_frames:
            # рдпрджрд┐ рдЬрд╝реНрдпрд╛рджрд╛ рдлреНрд░реЗрдореНрд╕ рд╣реИрдВ, рддреЛ рдЯреНрд░рдВрдХреЗрдЯ рдХрд░реЗрдВ
            mel_db = mel_db[:, :target_frames]

        # рдореЙрдбрд▓ рдХреЛ (1, 128, 173) рдЖрдХрд╛рд░ рдХрд╛ 3D рдЗрдирдкреБрдЯ рдЪрд╛рд╣рд┐рдПред
        # np.expand_dims(mel_db, 0) рдмреИрдЪ рдбрд╛рдпрдореЗрдВрд╢рди (axis=0 рдкрд░) рдЬреЛрдбрд╝рддрд╛ рд╣реИред
        return np.expand_dims(mel_db, 0) 

    except Exception as e:
        st.error(f"рдСрдбрд┐рдпреЛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдореЗрдВ рд╡рд┐рдлрд▓: {str(e)}")
        return None

# Streamlit рдкреЗрдЬ рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди
st.set_page_config(page_title="рдмреЗрдмреА рдХреНрд░рд╛рдИ рдбрд┐рдЯреЗрдХреНрдЯрд░", page_icon="ЁЯС╢", layout="centered")

# рдореЙрдбрд▓ рдФрд░ рдПрдирдХреЛрдбрд░ рдХреЛ рдХреИрд╢ рдХрд░реЗрдВ рддрд╛рдХрд┐ рд╣рд░ рдмрд╛рд░ рдРрдк рд▓реЛрдб рд╣реЛрдиреЗ рдкрд░ рдЙрдиреНрд╣реЗрдВ рдлрд┐рд░ рд╕реЗ рд▓реЛрдб рди рдХрд░рдирд╛ рдкрдбрд╝реЗ
@st.cache_resource
def load_all():
    model = load_model_anyway("best_model.h5") # рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдпрд╣ рдкрде рд╕рд╣реА рд╣реИ
    encoder = joblib.load("label_encoder.pkl") # рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдпрд╣ рдкрде рд╕рд╣реА рд╣реИ
    if model:
        # рдореЙрдбрд▓ рдХреЗ рдЕрдкреЗрдХреНрд╖рд┐рдд рдЗрдирдкреБрдЯ рд╢реЗрдк рдХреЛ рд▓реЙрдЧ рдХрд░реЗрдВ (рдбреАрдмрдЧрд┐рдВрдЧ рдХреЗ рд▓рд┐рдП)
        st.write(f"рдореЙрдбрд▓ рд▓реЛрдб рд╣реЛ рдЧрдпрд╛ рд╣реИред рдЕрдкреЗрдХреНрд╖рд┐рдд рдЗрдирдкреБрдЯ рд╢реЗрдк: {model.input_shape}")
    return model, encoder

# рдореЙрдбрд▓ рдФрд░ рдПрдирдХреЛрдбрд░ рд▓реЛрдб рдХрд░реЗрдВ
model, encoder = load_all()

# рдРрдк рдХрд╛ UI
st.title("ЁЯС╢ рдмреЗрдмреА рдХреНрд░рд╛рдИ рдПрдирд╛рд▓рд╛рдЗрдЬрд╝рд░")
st.write("рдПрдХ рдмрдЪреНрдЪреЗ рдХреЗ рд░реЛрдиреЗ рдХреА WAV рдлрд╝рд╛рдЗрд▓ (2-5 рд╕реЗрдХрдВрдб) рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ")

# рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдбрд░ рд╡рд┐рдЬреЗрдЯ
uploaded_file = st.file_uploader("рдлрд╝рд╛рдЗрд▓ рдЪреБрдиреЗрдВ", type=["wav"])

# рдпрджрд┐ рдХреЛрдИ рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХреА рдЧрдИ рд╣реИ
if uploaded_file:
    st.audio(uploaded_file) # рдЕрдкрд▓реЛрдб рдХреА рдЧрдИ рдСрдбрд┐рдпреЛ рдЪрд▓рд╛рдПрдВ
    
    # рдЕрд╕реНрдерд╛рдпреА рд░реВрдк рд╕реЗ рдлрд╝рд╛рдЗрд▓ рдХреЛ рд╕реЗрд╡ рдХрд░реЗрдВ рддрд╛рдХрд┐ librosa рдЙрд╕реЗ рдкрдврд╝ рд╕рдХреЗ
    temp_file_path = "temp.wav"
    with open(temp_file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # рдлреАрдЪрд░реНрд╕ рдирд┐рдХрд╛рд▓реЗрдВ
    features = extract_features(temp_file_path)
    
    if features is not None:
        # рдирд┐рдХрд╛рд▓реЗ рдЧрдП рдлреАрдЪрд░реНрд╕ рдХреЗ рд╢реЗрдк рдХреЛ рд▓реЙрдЧ рдХрд░реЗрдВ (рдбреАрдмрдЧрд┐рдВрдЧ рдХреЗ рд▓рд┐рдП)
        st.write(f"рдирд┐рдХрд╛рд▓реЗ рдЧрдП рдлреАрдЪрд░реНрд╕ рдХрд╛ рд╢реЗрдк: {features.shape}")

        # рдЗрдирдкреБрдЯ рд╢реЗрдк рдХреА рд╕рдВрдЧрддрддрд╛ рдЬрд╛рдВрдЪреЗрдВ
        # рдореЙрдбрд▓ рдХреЗ рдЕрдкреЗрдХреНрд╖рд┐рдд рдЗрдирдкреБрдЯ рд╢реЗрдк рдХрд╛ рдкрд╣рд▓рд╛ рддрддреНрд╡ (None) рдмреИрдЪ рд╕рд╛рдЗрдЬрд╝ рд╣реИ,
        # рдЗрд╕рд▓рд┐рдП рд╣рдо рдЗрд╕рдХреА рддреБрд▓рдирд╛ рдирд╣реАрдВ рдХрд░рддреЗ, рдмрд▓реНрдХрд┐ рдмрд╛рдХреА рдЖрдпрд╛рдореЛрдВ рдХреА рддреБрд▓рдирд╛ рдХрд░рддреЗ рд╣реИрдВред
        # рд╣рдо рдпрд╣рд╛рдБ len(model.input_shape) == len(features.shape) рдХреА рдЬрд╛рдВрдЪ рднреА рдХрд░ рд░рд╣реЗ рд╣реИрдВ рдХреНрдпреЛрдВрдХрд┐
        # model.input_shape рдореЗрдВ None рд╣реЛ рд╕рдХрддрд╛ рд╣реИред
        # features.shape рдореЗрдВ 1 рд╣реЛрдЧрд╛ рдХреНрдпреЛрдВрдХрд┐ рд╣рдордиреЗ np.expand_dims(mel_db, 0) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рд╣реИред
        # рдЗрд╕рд▓рд┐рдП, рд╣рдо рдХреЗрд╡рд▓ рдЕрдВрддрд┐рдо рджреЛ рдЖрдпрд╛рдореЛрдВ (128 рдФрд░ 173) рдХреА рддреБрд▓рдирд╛ рдХрд░реЗрдВрдЧреЗред
        if model.input_shape and \
           model.input_shape[1] == features.shape[1] and \
           model.input_shape[2] == features.shape[2]: # рдХреЗрд╡рд▓ 128 рдФрд░ 173 рдХреА рддреБрд▓рдирд╛ рдХрд░реЗрдВ
            # рдпрджрд┐ рд╢реЗрдк рд╕рдВрдЧрдд рд╣реИрдВ, рддреЛ рдкреНрд░реЗрдбрд┐рдХреНрд╢рди рдХрд░реЗрдВ
            pred = model.predict(features, verbose=0)[0]
            top_idx = np.argmax(pred)
            st.success(f"рд╕рдмрд╕реЗ рд╕рдВрднрд╛рд╡рд┐рдд: {encoder.classes_[top_idx]} ({pred[top_idx]*100:.1f}%)")
        else:
            # рдпрджрд┐ рд╢реЗрдк рдореИрдЪ рдирд╣реАрдВ рдХрд░рддреЗ рддреЛ рдПрд░рд░ рджрд┐рдЦрд╛рдПрдВ рдФрд░ рд░реБрдХреЗрдВ
            st.error(f"рдЗрдирдкреБрдЯ рд╢реЗрдк рдорд┐рд╕рдореИрдЪ! рдореЙрдбрд▓ рдХреЛ {model.input_shape} рдЪрд╛рд╣рд┐рдП рд▓реЗрдХрд┐рди {features.shape} рдорд┐рд▓рд╛ред "
                     f"рдХреГрдкрдпрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдСрдбрд┐рдпреЛ рдХреА рд▓рдВрдмрд╛рдИ (2-5 рд╕реЗрдХрдВрдб рдЕрдиреБрд╢рдВрд╕рд┐рдд) рдФрд░ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдореЙрдбрд▓ рдХреА рдЯреНрд░реЗрдирд┐рдВрдЧ рд╕реЗ рдореЗрд▓ рдЦрд╛рддреА рд╣реИред")
            st.stop() # рдРрдк рдХреЛ рдЖрдЧреЗ рдмрдврд╝рдиреЗ рд╕реЗ рд░реЛрдХреЗрдЧрд╛ рдпрджрд┐ рд╢реЗрдк рдЧрд▓рдд рд╣реИ
    
    # рдЕрд╕реНрдерд╛рдпреА рдлрд╝рд╛рдЗрд▓ рдХреЛ рд╣рдЯрд╛ рджреЗрдВ
    if os.path.exists(temp_file_path):
        os.remove(temp_file_path)

